# Tidy evaluation {#sec:tidy-eval}

The so-called [“tidyverse”](https://www.tidyverse.org) refers to a number of R packages designed to work well together and based on similar designs that can all be considered domain-specific languages in themselves. These packages include `dplyr`, `tidyr` and `ggplot2` and mainly consist of functions that do non-standard evaluation. The way they manage non-standard evaluation is consistent among the packages and based on what they call “tidy evaluation”, which essentially relies on two features implemented in the `rlang` package: quosures and quasi-quotation.

## Quosures

The `rlang` package provided functions to replace `quote` and `substitute` that create quosures—expressions based on formulas that carry with them their environment—instead of expressions. To create a quosure from an expression, you use `quo`:

```{r}
q <- rlang::quo(2 * x)
q
```

Inside a function call, the quosure analogue to `substitute` is `enquo`:

```{r}
f <- function(expr) rlang::enquo(expr)
q <- f(2 * x)
q
```

In both of these examples, the scope associated with the quosure is the global environment because this is the level at which the expression is written.

A quosure is just a special type of formula, so we can access one as we did in the previous section to get the environment and expression

```{r}
q[[2]]
environment(q)
```

but `rlang` provides functions for working with quosures that make the intent of our code clearer. To get the expression out of a quosure, we use the function `UQE`—unquote expression:

```{r}
rlang::UQE(q)
```

I honestly think the name is a bit unfortunate since the *un*-quote function returns a quoted expression, but it does strip away the quosure-ness and gives us a raw expression. There is another unquote function, `UQ`, that *does* unquote an expression in the sense of evaluating it, but it has a different purpose that we get to in the next section.

Getting the environment associated with a quosure can be done using `environment` as we saw above, but the `rlang` function for this is `get_env`:

```{r}
rlang::get_env(q)
```

With quosures you can no longer evaluate them with `eval`. A quosure is a formula, and the result of evaluating a formula is the formula itself.

```{r}
eval(q)
```

Instead, you need to use the function `eval_tidy`

```{r}
x <- 1
rlang::eval_tidy(q)
x <- 2
rlang::eval_tidy(q)
```

The quosure is evaluated inside the environment it is associated with. We created this quosure, `q`, inside function `f`, but its environment is the global environment, so when we modify this, by changing `x`, it affects the result of evaluating `q`.

If we create a quosure inside a local function scope, it will remember this context—just like a closure. For example, if we define function `f` as this

```{r}
f <- function(x, y) rlang::quo(x + y + z)
```

the quosure will know the function parameters `x` and `y` from when `f` is called, but will have to find `z` elsewhere. Consider the contrast between evaluating the quosure and the expression `x + y + z` directly:

```{r}
q <- f(1, 2)
x <- y <- z <- 3
rlang::eval_tidy(q) # 1 + 2 + 3
x + y + z # 3 + 3 + 3
```

Just as `eval`, `eval_tidy` lets you provide a list, data frame, or environment with bindings from variables to values. When you do this, the values you provide will overrule the variables in the quosure’s environment—an effect known as *over-scoping*. Consider this:

```{r}
x <- 1:4
y <- 1:4
q <- quo(x+y)
rlang::eval_tidy(q)
rlang::eval_tidy(q, list(x = 5:8))
```

The quosure `q` is bound to the global environment, so when we evaluate it, `x` and `y` are both `1:4`. However, when we provide the second argument to `eval_tidy`, we can override the value of `x` to `5:8`. You will recognise this feature from `dplyr` where you have access to columns in data frames in arguments you provide to the functions there and these columns over rule any global variable that might otherwise have been used.

This, of course, can also be used to override variables in a function call with function parameters. Consider these two functions:

```{r}
f <- function(expr,x) {
  q <- rlang::enquo(expr)
  rlang::eval_tidy(q)
}
g <- function(expr,x) {
  q <- rlang::enquo(expr)
  rlang::eval_tidy(q, environment())
}
f(x + y, x = 5:8)
g(x + y, x = 5:8)
```

The function `f` simply evaluates the quosure in its scope, which doesn’t contain the function parameter `x`, while the function `g` over-scopes with the function environment, making the variable `x` refer to the function parameter rather than the global parameter.

The expression you evaluate with `eval_tidy` doesn’t have to be a quosure. The function is equally happy to evaluate bare expressions, and then it behaves just like `eval`:

```{r}
rlang::eval_tidy(quote(x + y))
```

Just like `eval`, `eval_tidy` takes a third argument that will behave as the enclosing scope.  This is used for bare expressions—those created with `quote`

```{r}
rlang::eval_tidy(quote(xx), env = list2env(list(xx = 5:8)))
```

but not with quosures

```{r}
rlang::eval_tidy(quo(xx), env = list2env(list(xx = 5:8)))
```

If you want to create a closure with over-scoping, i.e. you want to create a function that evaluates a quosure where it first finds local variables and then look in the quosure’s environment, you cannot directly call `eval_tidy` when creating the function. This would ask R to attempt to evaluate the closure, but you do not yet have the variables you need—those are provided when you call the closure. Instead, you can separate the bare expression and the environment of the quosure using `UQE` and `get_env`, respectively. Consider the function `make_funciton` below:

```{r}
make_function <- function(args, body) {
  body <- rlang::enquo(body)
  rlang::new_function(args, rlang::UQE(body), rlang::get_env(body))
}
f <- function(z) make_function(alist(x=, y=), x + y + z)
g <- f(z = 1:4)
g
g(x = 1:4, y = 1:4)
```

Here, `make_function` takes two arguments, a pair list of arguments and an expression for the body of a function. It is a little more primitive than the lambda expressions we wrote in the previous chapter, but it is essentially doing the same thing, in this example I am just focusing on the closure we create rather than on language design issues. We translate the function body into a quosure, which guarantees that we have an environment associated with it. In the function we create using `new_function`, however, we strip the environment from the quosure to create the body of the new function, but we assign the function’s environment to be the quosure environment.

In the function `f` we have a local scope that knows the value of `z` and in this scope we create a new function. The quosure we get from this is associated with the local `f` scope, so it also knows about `z`. When call `g` we provide variables `x` and `y`, but the `z` value is taken from the local scope of `f`.

Of course, if called directly, there isn’t any difference between using the caller’s environment or the quosure’s environment 

```{r}
make_function_quo <- function(args, body) {
  body <- rlang::enquo(body)
  rlang::new_function(args, rlang::UQE(body), rlang::get_env(body))
}
make_function_quote <- function(args, body) {
  body <- substitute(body)
  rlang::new_function(args, body, rlang::caller_env())
}
g <- make_function_quo(alist(x=, y=), x + y)
h <- make_function_quote(alist(x=, y=), x + y)
g(x = 1:4, y = 1:4)
h(x = 1:4, y = 1:4)
```

However, consider a more involved example, where we collect expressions in a list and have a function for translating all the expressions into functions that we can then apply over values using the `invoke_map` function from the `purrr` package. We can construct the expressions like this, using the linked lists structure we have previously used:

```{r, echo=FALSE}
cons <- function(elm, lst) list(car=elm, cdr=lst)
lst_length <- function(lst) {
  len <- 0
  while (!is.null(lst)) {
    lst <- lst$cdr
    len <- len + 1
  }
  len
}
lst_to_list <- function(lst) {
  v <- vector(mode = "list", length = lst_length(lst))
  index <- 1
  while (!is.null(lst)) {
    v[[index]] <- lst$car
    lst <- lst$cdr
    index <- index + 1
  }
  v
}
```

```{r}
expressions <- function() list(ex = NULL)
add_expression <- function(ex, expr) {
  ex$ex <- cons(rlang::enquo(expr), ex$ex)
  ex
}
```

Translating the expressions into functions is straightforward, we just need to reverse the resulting list if we want the functions in the order we add them, since we prepend expressions when we use the linked lists:

```{r}
make_functions <- function(ex, args) {
  results <- vector("list", length = lst_length(ex$ex))
  i <- 1; lst <- ex$ex
  while (!is.null(lst)) {
    results[[i]] <- 
      rlang::new_function(args, rlang::UQE(lst$car), 
                           rlang::get_env(lst$car))
    i <- i + 1
    lst <- lst$cdr
  }
  rev(results)
}
```

With this small domain-specific language for collecting expressions, we can write a function that creates expressions for computing y-coordinates of a line given an intercept:

```{r}
make_line_expressions <- function(intercept) {
  expressions() %>% 
    add_expression(coef + intercept) %>%
    add_expression(2*coef + intercept) %>% 
    add_expression(3*coef + intercept) %>% 
    add_expression(4*coef + intercept)
}
```

The expressions know the intercept when we call `make_line_expressions`—that is the intent at least—but the coefficient should be added later in a function call. We can create the functions for the expressions using another function:

```{r}
eval_line <- function(ex, coef) {
  ex %>% make_functions(alist(coef=)) %>%
    purrr::invoke_map(coef = coef) %>% unlist
}
```

We can now pipe these functions together to get points on a line:

```{r}
make_line_expressions(intercept = 0) %>% eval_line(coef = 1)
make_line_expressions(intercept = 0) %>% eval_line(coef = 2)
make_line_expressions(intercept = 1) %>% eval_line(coef = 1)
```

All works as intended here, but what would happen if we used quotes instead? It is simple to write the corresponding functions:

```{r}
add_expression <- function(ex, expr) {
  ex$ex <- cons(substitute(expr), ex$ex)
  ex
}
make_functions <- function(ex, args) {
  results <- vector("list", length = lst_length(ex$ex))
  i <- 1; lst <- ex$ex
  while (!is.null(lst)) {
    results[[i]] <- rlang::new_function(args, lst$car, rlang::caller_env())
    i <- i + 1
    lst <- lst$cdr
  }
  rev(results)
}
```

We will get an error if we try to use them as before, however:

```{r}
make_line_expressions(intercept = 0) %>% eval_line(coef = 1)
```

The reason for this is easy to see once we consider which environments contain information about the intercept. This variable lives in the scope of calls to `make_line_expressions`, but when we create the functions we do so by calling `make_functions` from inside `eval_line`. The functions are created with `eval_line` local environments as their closures, and `intercept` is not found there.

In general, it is safer to use quosures than bare expressions for non-standard evaluation exactly because they carry their environment along with them, alleviating many of the problems we otherwise have with keeping track of which environment to evaluate expressions in.

A final thing I want to mention before we move on to the next topic is the function `quos`. This function works as `quo` but for a sequence of arguments that are returned as a list of quosures.

```{r}
rlang::quos(x, y, x+y)
```

The primary use of `quos` is to translate the three-dots argument into a list of quosures:

```{r}
f <- function(...) rlang::quos(...)
f(x, y, z)
```

## Quasi-quoting

The final topic of this chapter involves *quasi-quoting*, which simply means that we create quoted expression where we do not quote *everything* but evaluate some parts of expressions. When we directly call functions that do non-standard evaluation, we can usually provide expressions exactly as we want them, but as soon as we start using such non-standard evaluation functions in programs where we call them from other functions, we need some flexibility in how we construct expressions. We can do this with meta-programming where we modify `call` objects, but a better approach is implemented in the `rlang` package, the so-called *quosi-quoting*.

Consider a simple, but not unrealistic, example. We have a data frame and we want to filter away rows where a given column has missing data. We can do this using `dplyr`’s `filter` function like this:

```{r}
df <- tibble::tribble(
  ~x, ~y,
   1,  1,
  NA,  2,
   3,  3,
   4, NA,
   5,  5,
  NA,  6,
   7, NA
)
df %>% dplyr::filter(!is.na(x))
df %>% dplyr::filter(!is.na(y))
```

Here, we are using the same code for two different variables. It is very simple code so we probably wouldn’t write a function to avoid the duplication, but for more complicated pipelines we would—so for the sake of argument let us just imagine that we want to replace the pipeline with a function. We could attempt to write it like this:

```{r}
filter_on_na <- function(df, column) {
  column <- substitute(column)
  df %>% dplyr::filter(!is.na(column))
}
df %>% filter_on_na(x)
```

We use `substitute` to translate the column name into a symbol and then apply the `filter` pipeline. It doesn’t work, of course

```{r}
df %>% filter_on_na(x)
```

and the reason is simply that `filter` does non-standard evaluation as well and translate the predicate `!is.na(column)` into this exact expression. So it needs to know the variable `column`. Now, since `filter` evaluates its argument as a quosure, it *can* find the variable `column`, but it finds that this is a symbol—it is in this case the symbol `x`—but that is not what we want it to see. We want `filter` to see the column `x`, but that is not how `filter` works.

What we want to do is to substitute the symbol held in the variable `column` into the expression/quosure that `filter` sees. We can do this with the “bang-bang” operator `!!`:

```{r}
filter_on_na <- function(df, column) {
  column <- rlang::enexpr(column)
  df %>% dplyr::filter(!is.na(!!column))
}
df %>% filter_on_na(x)
df %>% filter_on_na(y)
```

This operator unquotes the following expression, evaluate it, and put the result into the quoted expression that `filter` sees. So the value of `column`, rather than the symbol `column`, gets insert into `!is.na(!!column)``.

You will have noticed that I used a different function to create the quoted column name. In the `rlang` package there are two functions that behave like `quote` and `substitute` in that they create bare expressions but they allow quasi-quoting with the bang-bang operator, something `substitute` and `quote` do not. Consider the functions `f` and `g` defined like this:

```{r}
f <- function(x) substitute(x)
g <- function(x) rlang::enexpr(x)
```

Called directly, both will return the expression we give as the parameter `x`, but consider the case where we call them from another function, `h`, where we want to substitute its parameter for the parameter `x`:

```{r}
h <- function(func, var) func(!!var)
h(f, quote(x))
h(g, quote(x))
```

In `f`, where we use `substitute`, we get the expression `!!var` back, but in function `g`, where we use `enexpr`, we get the substitution done and get the desired result `x`.

The function `enexpr` works like `enquo` to translate function parameters into expressions, but translate them into bare expressions rather than quosures. The analogue to `quo`, that takes an expression directly and create a quosure, we have `expr`, which create a bare expression—like `quote`—but allows quasi-quotation.

```{r}
x <- y <- 1
quote(2 * x + !!y)
rlang::expr(2 * x + !!y)
rlang::quo(2 * x + !!y)
```

You have to be a little bit careful when using the bang-bang operator. It is built from the negation operator, `!`, which has a very low precedence. The only operators with lower precedence are the logical operators and assignments. This mean that if you try to unquote `x` in the expression `x + y`, you will in fact be unquoting the entire expression if you simply write `!!x + y`. You only get `!!` bound to only `x` if the operator you use in the expression is a logical operator.

```{r}
x <- y <- 2
rlang::expr(!!x + y)
rlang::expr(!!x & y)
```

You can get around this problem using parentheses, or you can use the function-variant of unquoting, `UQ`:

```{r}
rlang::expr(UQ(x) + y)
```

When we translate a function argument into an expression, with `enexpr`, or a quosure, with `enquo`, the bang-bang operator or the `UQ` function will substitute the results of expressions into the expressions/quosures we create, which is why the second `filter_on_na` function worked.

A final quasi-quotation function you must now is `UQS`. This function behaves as `UQ` in that it evaluates its arguments and put the result into a quoted expression, but it is intended for splicing a list of quosures into a function call.

Consider this example:

```{r}
args <- rlang::quos(x = 1, y = 2)
q <- rlang::expr(f(rlang::UQS(args)))
q
```

Here, we create a list of quosures for arguments `x` and `y` and create an expression that calls the function `f` with these arguments. The `UQS` function is what splices the arguments into the expression for the function call. Using `UQ`, we would get a different expression:

```{r}
q <- rlang::expr(f(rlang::UQ(args)))
q
```

Just as for `UQ`, though, there is an operator version of `UQS`, the triple-bang operator `!!!`

```{r}
q <- rlang::expr(f(!!!args))
q
```

To see `UQS` in action we consider another toy example. We write a function for evaluating the mean of an expression given a data frame. Imagine that we want to map over several data frames and compute the mean of the same expression or something like that. We construct a function for this that evaluates an expression we capture as a quosure and computes the mean of the expression in a data frame, using additional arguments to modify the call to `mean`.

```{r}
mean_expr <- function(ex, ...) {
  ex <- rlang::enquo(ex)
  extra_args <- rlang::dots_list(...)
  mean_call <- rlang::expr(with(data, mean(UQE(ex), !!!extra_args)))
  rlang::new_function(args = alist(data=), 
                      body = mean_call,
                      env = rlang::get_env(ex))
}
mean_sum <- mean_expr(x + y, na.rm = TRUE)
mean_sum
```

There’s a few new things here. We use `dots_list` to evaluate the arguments in the `...` parameter. We could deal with this in other ways, but we don’t necessarily want them to be evaluated lazily and we just want a list to use as extra arguments to a call to `mean`. We create an expression from the `ex` parameter. Here, we wrap the bare expression in `ex` inside an expression that involves the `with` function to include data in the form of a data frame. We use the `!!!` operator to splice the additional parameters into the call to `mean`. We then construct a new function that takes a single argument, `data`, evaluates the `with(mean(...))` expression in its body, and is evaluated in the scope where `ex` was defined.

We can test it with the data frame we created above:

```{r}
df
mean_sum(df)
```

To see that the environment we evaluated the expression in is where it was defined, we can write a function to capture a parameter in a local scope and see that this scope is available when we call the mean function:

```{r}
f <- function(z) mean_expr(x + y + z, na.rm = TRUE, trim = 0.1)
g <- f(z = 1:7)
g
g(df)
```

Using quosures and quasi-quotes alleviate many of the problems you can have with keeping track of environments for non-standard evaluation, and I strongly suggest that you use these instead of the bare R `quote` and `substitute` approach. They do not, however, fix the problem with deciding when to quote arguments and with calling functions that translate arguments into expressions. If you call a function that uses `enquo` from a function where you have already quoted the argument, then you get it double-quoted:

```{r}
f <- function(expr) rlang::enquo(expr)
g <- function(expr) f(rlang::enquo(expr))
f(x + y)
g(x + y)
rlang::eval_tidy(f(x + y), list(x = 1, y = 2))
rlang::eval_tidy(g(x + y), list(x = 1, y = 2))
```

Here, the solution is as before: if you need to call functions with already-quoted expressions, make two versions, one that expects it argument to be quoted and one that does it for you.
